models:
  faster-whisper:
    variant: faster-whisper
    name: large-v3
    framework: ctranslate2
    device: cuda
    batch_size: 8
    output_json: faster-whisper_large-v3_results.json
    output_dir: results/reports

  openai-whisper:
    variant: openai-whisper
    name: large-v3
    framework: pytorch
    device: cuda
    batch_size: 8
    output_json: openai-whisper_large-v3_results.json
    output_dir: results/reports

  whisper-cpp:                 # ðŸ‘ˆ Add this section
    variant: whisper-cpp
    name: large-v3                 # whisper.cpp supports tiny/base/small/medium/large
    framework: ggml
    device: cpu
    batch_size: 1
    output_json: whisper-cpp_tiny_results.json
    output_dir: results/reports
