models:
  faster-whisper:
    name: large-v3
    framework: ctranslate2
    device: cuda
    batch_size: 8

  openai-whisper:
    name: large-v3
    framework: pytorch
    device: cuda
    batch_size: 8

  whisper-jax:
    name: large-v2
    framework: flax
    device: cuda
    batch_size: 8

  whisperx:
    name: large-v2  # or large-v3 if supported, check docs
    framework: whisperx
    device: cuda
    batch_size: 8
